*******************************************************************************

*******************************************************************************

-------------------------------------------------------------------------------

Version something:

- DONE: Transforms are now "cached". Transform can be linked to grip
  object, which can be used to update transforms.

- DONE: Redesign nodes: "immovable" instances having only Model
  matrix, movable instances with pos & rot, etc. Now we have Bone, need
  just static bone hierarchies...

- DONE: Objects without mesh & mat... Static objects... "Bones" are
  now objects without shape. So, missing static bone (hierarchy)...

- DONE: Make Node.grip a property, so that it can warn if trying to move
  static objects.

- DONE: Transparent objects: Drawn back-to-front - With current Batch
  implementation, this can be done.

- DONE: "...Also, now e.g. projection matrix is written for each object, but in
  reality there is only need to write it again if camera perspective
  changes. As user may want to change camera without warning, a nice
  compromise would be writing things like these at the start of rendering
  phase. Secondly, we need ModelView matrix, so at the moment it is
  probably simpler just to send camera to instance rendering.
  
  * Comment: Projection and View matrices are written once when starting
    to render a batch. Because batch can include shader switch, and because
    matrices are not necessarily shared between shaders, we dont take risks,
    but write them.

- DONE: Multi-shader layers & scenes... Or should it be implemented with
  'multi-shader shader'? (Current Batch processing mechanism now implements
  this)

- DONE: Modified comment cutting line in blob/wavefront.d, which was causing
  segfault when compiling with -release flag.

- DONE: Found bug in Transform while profiling, it was still updating the
  matrix all the time (missing 'last_update = frame' line). Now it works.

- DONE: Profiling (wolfish). Findings:

  The biggest time consumer is - glClear!!! :o It takes like 5x more time
  than drawing the scene (which is the second largest time consumer). In
  drawing, the biggest time consumer is viewspace projection, which is done
  for visibility check.
  
  BUT: I am pretty sure glClear() time consumption is only a symptom, not
  the cause. Removing glClear() call does not affect to FPS, but if we
  don't draw anything, glClear() takes no time. See e.g.
  
        https://forums.ouya.tv/discussion/491/14ms-glclear
  
  Also, moving glClear() behind SwapBuffers does not have effect to busy/idle
  times. More likely it is faint hint how much time was spent on GPU side (but
  of course, GPU has also other load than the game).
  
  This is how profiling info looks like (at the top, call tree time only):

        1817170176     void engine.game.startdraw()
        1816984147     void engine.render.start()
        1816631574     nothrow @nogc void engine.render.util.checkgl!(extern (C) nothrow @nogc void function(uint)* derelict.opengl3.functions.glClear, uint).checkgl(uint)
         498454577     void wolfish.main().draw()
         498253902     void engine.render.layer.CollectRender.draw()
         311839398     void engine.render.layer.BasicNodeGroup.collect(engine.render.view.View, engine.render.batch.BatchGroup)
         307202259     _D6engine6render5layer14BasicNodeGroup7collectMFC6engine6render4view4ViewC6engine6render5batch10BatchGroupZ14__foreachbody3MFKC6engine6render4node4NodeKbZi
         295646258     void engine.render.node.Node.project(engine.render.view.View)
         272531709     gl3n.linalg.Vector!(float, 3).Vector engine.render.view.View.viewspace(gl3n.linalg.Matrix!(float, 4, 4).Matrix, gl3n.linalg.Vector!(float, 3).Vector)
         268724416     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.view.View.mModelView(gl3n.linalg.Matrix!(float, 4, 4).Matrix)
         247450932     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.view.Camera.mView()
         212859522     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.Transform.mModel()
         208074024     void engine.game.init(int, int)
         208073418     void engine.game.init(immutable(char)[], int, int)
         183702676     void engine.render.batch.BatchGroup.draw(engine.render.view.View)
         183605914     void engine.render.batch.Batch.draw(engine.render.view.View)
         181722518     void engine.render.shaders.base.Shader.render(engine.render.transform.Transform, engine.render.material.Material, engine.render.shaders.base.Shader.VAO)
         171131557     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.Grip.matrix()
         167943665     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.getmatrix(gl3n.linalg.Vector!(float, 3).Vector, gl3n.linalg.Vector!(float, 3).Vector, gl3n.linalg.Vector!(float, 3).Vector)
         154587816     void engine.render.shaders.defaults.Default.render(engine.render.transform.Transform, engine.render.shaders.base.Shader.VAO)
         140329826     nothrow @nogc void engine.render.util.checkgl!(extern (C) nothrow @nogc void function(uint, int, uint, const(void)*)* derelict.opengl3.functions.glDrawElements, uint, uint, uint, ).checkgl(uint, uint, uint, )
         140324482     void engine.render.shaders.base.Shader.IBO.draw()
               ...     ...

  There is still some strange things: wolfish (and cylinderium) generally run
  at least as fast as pacman, although it uses much more complicated CPU and
  GLSL code. I need to investigate 2D performance, as because of GUI elements
  it will matter to 3D games, too.

-------------------------------------------------------------------------------

Version something:

- DONE: Naming conventions - modified class names somewhat according
  to naming used by:
  
        https://github.com/gameplay3d/GamePlay/wiki

- DONE: Render batches: nodes can now be retrieved from scene graph(s)
  to batches, and then feed them to shader(s).

- NOTE: Text rendering not working!

- DONE: At lowest levels, there is a batch. It's a list of instances, rendered
  by the same shader. This is something like Layer and Scene are at the moment.
  I'm pretty sure this kind of mechanism does not go anywhere. At the top
  level, you have scene data. Mapping these together is the hard part.

  Anyways, it's quite clear that the current TextBox implementation prevents
  me to implement such batch processing. So, it would be very, very
  important to change this. Think hard how to make it happen. If we implement
  a Blitter class to blit 2D images?

- DONE: I could make a block containing OpenGL settings (depth test on/off etc),
  apply it on shader change and put apply() as private method. This way
  you could tweak shader parameters at game side.

- DONE: Combine Layer and Scene... Somehow... And implement sort of worksets.
  The idea is to divide drawing to two separate phases. Programmer classifies
  the objects and puts them to different containers. For drawing, s/he chooses
  the strategies how objects from containers are moved to rendering.

-------------------------------------------------------------------------------

Version something:

- Somewhat done: I should go through code and correct indentation

- Shader: moved Shader class a little bit lower level, and added initial
  support for instanced drawing to interface.

- Remove color attribute from Material: it is meant to be instance-specific
  material modifier, analogous to Model matrix which is instance-specific
  transformation modifier. For example, for particle engines, we need
  instance specific struct, like:
  
        struct INSTANCE { mat4 model; vec4 color }

-------------------------------------------------------------------------------

Version something:

- Done: There is a great need to have improved compilation mechanism.
  That is, separating CPU-GPU interface parts (uniforms, attributes),
  interface between vertex and fragment shader, and have something to
  help "plugging" different vertex and fragment shaders together.

- Done: Stupid user error, the gl3n examples clearly instruct to transpose
  matrices when sending them to GPU. (Matrix multiplication order is different
  in GLSL than in D. It would be very nice that the multiplication order would
  follow some standard. Investigate this problem closer, and decide what to
  do (transpose when sending?))

- Somewhat done: Trying to make runtime configurable uniforms not working...
  Current solution is to open uniform setting outside. It is important to
  call shader activation to do this. Because of that, we need to improve
  the interface: exposing a method that does not work reliably is not
  an answer, and I don't want to add shader activation to all uniform
  settings, as they are called in performance critical parts (although
  the time missed to see that current shader is active is probably
  insignificant). It is just about principles.

- DONE: use size_t instead of ulong/uint (sizeof, length, ...)

-------------------------------------------------------------------------------

Version something:

- Done: Reducing vertex data size to improve GPU cache performance: Normals and
  UV coordinates could have smaller input precision:
  
  	* https://www.opengl.org/wiki/Vertex_Specification_Best_Practices#Attribute_sizes

- Done: Vertex data compression. There are bugs to fix, thought.

- Done: We now compute frustum planes every time, but it is only necessary
  when changing camera projection... Now Frustum (planes) are cached.

- Done: It might be good to separate exotic data formats needed in VBOs to
  their own source file.

- Done: Stupid user error, didn't change the field type at 2D shader side.
  (unsigned short does not work as UV coordinates. Colormaps on 3D models
  work without problem, but not on 2D objects (e.g. text and pacman).
  Investigate the problem. It is also true, that UV coordinates can be
  larger (absolute value) than 1.0, so it could be better to look for
  half floats.)

- Done: UV coordinates are sent as half floats

- Done: attrib function needs a mechanism to automatically choose correct attribute
  binding based on the Mesh.VERTEX types, just like uniforms work. Current
  implementation is a bit clumpsy, but it works.

- Done: "static if" now forces vertex data to be 32 bytes. It would be nice to
  have automatic padding, but even this is a step forward to improve GPU cache
  performance.

-------------------------------------------------------------------------------

Version something:

- Done: (GL) VAOs not working, maybe because of OpenGL version? No, it was
  just some missing code in certain positions.

- Done: Implement interleaved vertex attribute arrays. Interleaved data is
  definitely the easiest one from programming side, I just didnt know how
  to implement it when started developing the engine.

- Postponed: Joystick support; don't forget feedback. Sadly, my game controller
  has no force feedback.

- Done: Normal mapping

-------------------------------------------------------------------------------

Version something:

- Done: Wavefront obj files: Compute (face) normals, if they are missing

- Done: Shape class: We need Layer.Instance 'stencils', or color & texture
  in Mesh: most of time, at least texture is strictly bound to mesh, and will
  not work at other meshes.

- Done: Basic CPU-side bitmap manipulation

- Done: Object hierarchies: parenting cameras and lights to 3D space, very
  much needed feature. Somewhat done...

- Done: Currently, parent objects need not to be in draw lists. How about
  naming them bones?

- Done: Now matrix transform hierarchies are encapsulated under Bone
  class. It can be parented, and it is not part of Scene drawing lists.
  This may cause some problems to clean up "bones" when deleting
  3D objcts?

-------------------------------------------------------------------------------

Version something:

- Done: Fiber cleaning... Fiber list is now a class. Going out of scope
  destroys it.

- Done: Get rid of game.start() - now e.g. performance timers are created
  automatically if they are requested.

- Done: Fonts (TTF font loading & rendering)

- Done: Frustum culling using bounding spheres.

- Done: With Fibers, at least. Some sort of mechanism to create 'temporal'
  objects to layer: for example, explosions and such, which have known & limited
  life time.
  
- Done: Textures from sheet images

- Done: When creating Layer instances, pass them to shader to prepare them (filling
  missing values with reasonable defaults)

