*******************************************************************************

*******************************************************************************

-------------------------------------------------------------------------------

Version something:

- DONE: Emulated controller needs to push SDL joystick events (buttons, axes).
  Especially button events are important, as they are most probably used
  by GUI.

- DONE: Didnt work as well w/ transparent objects - Currently, sorting happens
  by (squared) distance to camera. Could it work as good just by Z-coordinate?
  Lets try it out.

- DONE: sin/cos to Translate

- DONE - see comments: Also, one architectural problem is that now - as it is
  right - 3D scene rendering state inherits from GPU rendering state, we loose
  the shader rendering interface. Currently I am casting state shader to
  correct type, but something better should be figured out.

        comment: 3D node rendering backend is now named "Feeder", a component
        to feed nodes to underlying shader.

- DONE: Joystick hotplugging (scan for added/removed joysticks)

- DONE: Layer.d does not exist anymore - Renderers in layer.d are incomplete
  hacks. Reorganize them, so, that move simplified solutions to ext/simple.d
  (that's the purpose of it)

- DONE: Also, it might be very good idea now to separate resource management,
  instead of keeping references in the batches. So, even thought it
  means more writing, we do the thing something like this:
  
        resources.model = shaderfamily.upload(mesh, material);
        resources.model.destination[pipeline] = pipeline.batchX;
        ...

  There is some ways to ease writing code, but anyways, the general idea
  is that references to uploaded models are found only from:

        1) nodes in scene
        2) resource lookup table for scene

  Destroying scene destroys also resources loaded for that.

- REJECTED: Skybox as an example of persistent objects in batches. Are they? Currently
  I am using own dedicated shader for skybox, so, they are not objects in
  batches, but own dedicated "batch".

- DONE: ViewProxy removed - View, ViewProxy: I havent used View proxy ever.
  There is a need to check if it has any use at all, or if we could simplify things a bit.

-------------------------------------------------------------------------------

Version something:

- DONE: Implement shader options somehow... State object, maybe? There is now
  options[] for both shader and state. Shader specific options are applied to
  all stages where shader is used. State specific options are only for the 
  specific state.

- DONE: (step forward shader family implementation) Mesh to intermediate format,
  separate VAO buffer creation to shader family upload. It can also be local
  buffer, as it is consumed during OpenGL download.  

- DONE: Bitmap: create renderer only if it is needed (user wants to tweak
  bitmap), as it is not that common that user wants to tweak loaded/created
  bitmaps.

- REJECTED: Bitmaps... In fact, if user creates empty bitmap, we can assume
  that s/he's going to draw something on that. But it's probably just too
  advanced and don't fix any problem or affect to performance in any way.
  Added complexity for nothing, or that how it feels now.

- DONE: 'fetch' target in makefile, to fetch dub libraries, to ease setting
  up a bit.

- DONE: (Animation) Implemented Translate class to create things like this:

        EasingCurve: http://qt-project.org/doc/qt-4.8/qeasingcurve.html

- DONE: Make game controller optional, at least for games that does not need
  them that much (i.e. have also keyboard control)

- DONE: Keyboard emulated game controller

-------------------------------------------------------------------------------

Version something:

- REJECTED: Picking objects by comparing depth at certain position after
  drawing that object is wonderfully slow. Amazingly slow. We reject this
  method for picking objects from 3D space.

- POSTPONED: Don't happen anymore, and no plans to use it -glVertexAttribPointer
  returns invalid enum when trying to use GL_INT_2_10_10_10_REV for normals &
  tangents.

- DONE: uniform() now has optional boolean for this - We could accept
  reading/writing inexisting uniforms in some cases, that is, store -1 to
  namecache. Certain uniforms are optional as their nature, it
  would not hurt if they do not exist in shader. This might not be a good idea
  in general - I want to catch errors early, and this could hide them, causing
  lots of time wasted in debugging.

- DONE: Fog

- DONE: RESOURCE TRACKING: Create mechanism to track living resources (number
  of meshes, nodes etc).

- DONE: Most probably not - Display lists are still useful??? Find it out.

- DONE: SkyBox - this was also nice practising about creating custom
  shaders on the fly.

- DONE: See comment below - There are segfaults when closing games. I am pretty
  sure they are caused by calling destructors, and some parts have already
  shutted down (like SDL). Needs investigation at some point, in case there is
  something more serious issues underlaying.
  
        COMMENT: It was caused by SDL, sort of. Earlier I implemented SDL_up
        flag when having problems with SDL_Surface deletion. I just never
        noticed that there is also joystick that calls SDL destroy. Hooking
        more destructors clearly showed out that static destructor - shutting
        down SDL - was called before Joystick destructor.
        
        FIX: I removed SDL shutdown from package destructor. That has now
        caused two hard-to-find bugs. It is much better to have more robust
        resource deallocation than having complete Init-Quit call pairs.

-------------------------------------------------------------------------------

Version something:

- INITIALLY DONE: Mipmaps

- INITIALLY DONE: Texture mipmaps: In 3D scenes, this could make them prettier.

- DONE: Texture loader class, holding texture sampling parameters

- DONE: Now there is Texture.Loader class to hold upload/sampling parameters.
  DESCRIPTION: Texture compression, mipmapping etc: there should be easy way
  to tell to rendering framework, for which purpose the texture is loaded
  and thus, how it can be postprocessed:
  
    - GUI elements and such: no compression, no mipmaps
    - 3D textures: compression and mipmapping

-------------------------------------------------------------------------------

Version something:

- FIXED: SDL resources (SDL_Surface, Fonts, ...) cause segfault at exit, if
  they are not freed (as destructors try to call SDL_FreeXXXX and SDL
  is already shut down).

- FIXED: Freeing fonts cause segfault (most probably, TTF is already closed when
  calling font destructor)

- DONE: Color for text

- DONE: Initial implementation of Node-specific material modifier added.

- DONE: Text rendering is now done by Canvas Widgets. TextBox currently has
  no color: it is waiting color to be added to instance specific modifier.

- DONE: At some point, there's a need to check that destructors are called at
  correct points. For example, when game level is changed, it would be
  very nice if the game frees GPU resources allocated at previous level.

- TEXT OUTPUT: Now there is another mechanism to feed drawing instructions
  to shader - Canvas. Canvas stores Widget type objects, which - when
  drawed - send drawing commands to shader. In scenes, Nodes are more or
  less passive data carriers.

  DESCRIPTION: This has troubled me a long time, is there anything I can
  do for it? Let's think about it.
  
  There is definitely many ways to get text in to screen. What method to use
  depends on the purpose.
  
  The first and most obvious two ways to render text are:
  
  1) Create a bitmap from given text, and add it to game world as a textured
     rectangle.

  2) Create bitmaps from letters, and add letters to game world as textured
     rectangles.

  These two ways create text that can be manipulated in the same ways as
  any other game world object. You can move them around, animate them and
  so on.
  
  Then, there is third way, which I have used so far. It works more like
  drawing letters to canvas-like object: you don't have 'handles' to
  separate letters, instead they are emitted by the text object.

  So: maybe I (need to) create all these methods? Well, at least two
  first ones are eventually mandatory, for example, for floating
  points and other written information in the game world itself. The
  third one then, at the moment it feels that it is related to creating
  rendering mechanism for GUI purposes: so, at the moment it feels
  totally worth to examine.

- In fact... If we would have support for "emitters" in nodes, we
  could feed objects like that to default shading process. Shader should
  just understand to query the emitted objects... Would be like "poor
  man's particle engine"...

- DONE: The way TextBox is implemented prevents us to implement shaders as
  instance batch processors. We may reconsider that implementation.

  * In fact, currently TextBox is more like special "Layer", not instance
  
  * I feel that the way TextBox works might be suitable for e.g. particle
    engines. So, instead of changing the TextBox implementation, we might
    improve architecture to deal with these kinds of things.

-------------------------------------------------------------------------------

Version something:

- DONE: BLOB handling: Currently, we use mechanism described here (second
  answer):

    http://stackoverflow.com/questions/5479691/is-there-any-standard-way-of-embedding-resources-into-linux-executable-image

  Everything is good and working, but I have been thinking to adopt a different
  method, just to cat exe and ZIP together, described here:

    http://stackoverflow.com/questions/4864866/c-c-with-gcc-statically-add-resource-files-to-executable-library

  The reason for this is to simplify building process and its dependencies a
  bit, to prepare for "dub'able" building.

  Solution:
  
    http://stackoverflow.com/questions/30418148/ziparchive-with-embedded-zip-concated-to-exe

- DONE: Preliminary dub support added. There is nothing wrong with make, but
  dub manages automatically dependencies to other D libraries.

-------------------------------------------------------------------------------

Version something:

- DONE: Transforms are now "cached". Transform can be linked to grip
  object, which can be used to update transforms.

- DONE: Redesign nodes: "immovable" instances having only Model
  matrix, movable instances with pos & rot, etc. Now we have Bone, need
  just static bone hierarchies...

- DONE: Objects without mesh & mat... Static objects... "Bones" are
  now objects without shape. So, missing static bone (hierarchy)...

- DONE: Make Node.grip a property, so that it can warn if trying to move
  static objects.

- DONE: Transparent objects: Drawn back-to-front - With current Batch
  implementation, this can be done.

- DONE: "...Also, now e.g. projection matrix is written for each object, but in
  reality there is only need to write it again if camera perspective
  changes. As user may want to change camera without warning, a nice
  compromise would be writing things like these at the start of rendering
  phase. Secondly, we need ModelView matrix, so at the moment it is
  probably simpler just to send camera to instance rendering.
  
  * Comment: Projection and View matrices are written once when starting
    to render a batch. Because batch can include shader switch, and because
    matrices are not necessarily shared between shaders, we dont take risks,
    but write them.

- DONE: Multi-shader layers & scenes... Or should it be implemented with
  'multi-shader shader'? (Current Batch processing mechanism now implements
  this)

- DONE: Modified comment cutting line in blob/wavefront.d, which was causing
  segfault when compiling with -release flag.

- DONE: Found bug in Transform while profiling, it was still updating the
  matrix all the time (missing 'last_update = frame' line). Now it works.

- DONE: Profiling (wolfish). Findings:

  The biggest time consumer is - glClear!!! :o It takes like 5x more time
  than drawing the scene (which is the second largest time consumer). In
  drawing, the biggest time consumer is viewspace projection, which is done
  for visibility check.
  
  BUT: I am pretty sure glClear() time consumption is only a symptom, not
  the cause. Removing glClear() call does not affect to FPS, but if we
  don't draw anything, glClear() takes no time. See e.g.
  
        https://forums.ouya.tv/discussion/491/14ms-glclear
  
  Also, moving glClear() behind SwapBuffers does not have effect to busy/idle
  times. More likely it is faint hint how much time was spent on GPU side (but
  of course, GPU has also other load than the game).
  
  This is how profiling info looks like (at the top, call tree time only):

        1817170176     void engine.game.startdraw()
        1816984147     void engine.render.start()
        1816631574     nothrow @nogc void engine.render.util.checkgl!(extern (C) nothrow @nogc void function(uint)* derelict.opengl3.functions.glClear, uint).checkgl(uint)
         498454577     void wolfish.main().draw()
         498253902     void engine.render.layer.CollectRender.draw()
         311839398     void engine.render.layer.BasicNodeGroup.collect(engine.render.view.View, engine.render.batch.BatchGroup)
         307202259     _D6engine6render5layer14BasicNodeGroup7collectMFC6engine6render4view4ViewC6engine6render5batch10BatchGroupZ14__foreachbody3MFKC6engine6render4node4NodeKbZi
         295646258     void engine.render.node.Node.project(engine.render.view.View)
         272531709     gl3n.linalg.Vector!(float, 3).Vector engine.render.view.View.viewspace(gl3n.linalg.Matrix!(float, 4, 4).Matrix, gl3n.linalg.Vector!(float, 3).Vector)
         268724416     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.view.View.mModelView(gl3n.linalg.Matrix!(float, 4, 4).Matrix)
         247450932     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.view.Camera.mView()
         212859522     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.Transform.mModel()
         208074024     void engine.game.init(int, int)
         208073418     void engine.game.init(immutable(char)[], int, int)
         183702676     void engine.render.batch.BatchGroup.draw(engine.render.view.View)
         183605914     void engine.render.batch.Batch.draw(engine.render.view.View)
         181722518     void engine.render.shaders.base.Shader.render(engine.render.transform.Transform, engine.render.material.Material, engine.render.shaders.base.Shader.VAO)
         171131557     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.Grip.matrix()
         167943665     gl3n.linalg.Matrix!(float, 4, 4).Matrix engine.render.transform.getmatrix(gl3n.linalg.Vector!(float, 3).Vector, gl3n.linalg.Vector!(float, 3).Vector, gl3n.linalg.Vector!(float, 3).Vector)
         154587816     void engine.render.shaders.defaults.Default.render(engine.render.transform.Transform, engine.render.shaders.base.Shader.VAO)
         140329826     nothrow @nogc void engine.render.util.checkgl!(extern (C) nothrow @nogc void function(uint, int, uint, const(void)*)* derelict.opengl3.functions.glDrawElements, uint, uint, uint, ).checkgl(uint, uint, uint, )
         140324482     void engine.render.shaders.base.Shader.IBO.draw()
               ...     ...

  There is still some strange things: wolfish (and cylinderium) generally run
  at least as fast as pacman, although it uses much more complicated CPU and
  GLSL code. I need to investigate 2D performance, as because of GUI elements
  it will matter to 3D games, too.

-------------------------------------------------------------------------------

Version something:

- DONE: Naming conventions - modified class names somewhat according
  to naming used by:
  
        https://github.com/gameplay3d/GamePlay/wiki

- DONE: Render batches: nodes can now be retrieved from scene graph(s)
  to batches, and then feed them to shader(s).

- NOTE: Text rendering not working!

- DONE: At lowest levels, there is a batch. It's a list of instances, rendered
  by the same shader. This is something like Layer and Scene are at the moment.
  I'm pretty sure this kind of mechanism does not go anywhere. At the top
  level, you have scene data. Mapping these together is the hard part.

  Anyways, it's quite clear that the current TextBox implementation prevents
  me to implement such batch processing. So, it would be very, very
  important to change this. Think hard how to make it happen. If we implement
  a Blitter class to blit 2D images?

- DONE: I could make a block containing OpenGL settings (depth test on/off etc),
  apply it on shader change and put apply() as private method. This way
  you could tweak shader parameters at game side.

- DONE: Combine Layer and Scene... Somehow... And implement sort of worksets.
  The idea is to divide drawing to two separate phases. Programmer classifies
  the objects and puts them to different containers. For drawing, s/he chooses
  the strategies how objects from containers are moved to rendering.

-------------------------------------------------------------------------------

Version something:

- Somewhat done: I should go through code and correct indentation

- Shader: moved Shader class a little bit lower level, and added initial
  support for instanced drawing to interface.

- Remove color attribute from Material: it is meant to be instance-specific
  material modifier, analogous to Model matrix which is instance-specific
  transformation modifier. For example, for particle engines, we need
  instance specific struct, like:
  
        struct INSTANCE { mat4 model; vec4 color }

-------------------------------------------------------------------------------

Version something:

- Done: There is a great need to have improved compilation mechanism.
  That is, separating CPU-GPU interface parts (uniforms, attributes),
  interface between vertex and fragment shader, and have something to
  help "plugging" different vertex and fragment shaders together.

- Done: Stupid user error, the gl3n examples clearly instruct to transpose
  matrices when sending them to GPU. (Matrix multiplication order is different
  in GLSL than in D. It would be very nice that the multiplication order would
  follow some standard. Investigate this problem closer, and decide what to
  do (transpose when sending?))

- Somewhat done: Trying to make runtime configurable uniforms not working...
  Current solution is to open uniform setting outside. It is important to
  call shader activation to do this. Because of that, we need to improve
  the interface: exposing a method that does not work reliably is not
  an answer, and I don't want to add shader activation to all uniform
  settings, as they are called in performance critical parts (although
  the time missed to see that current shader is active is probably
  insignificant). It is just about principles.

- DONE: use size_t instead of ulong/uint (sizeof, length, ...)

-------------------------------------------------------------------------------

Version something:

- Done: Reducing vertex data size to improve GPU cache performance: Normals and
  UV coordinates could have smaller input precision:
  
  	* https://www.opengl.org/wiki/Vertex_Specification_Best_Practices#Attribute_sizes

- Done: Vertex data compression. There are bugs to fix, thought.

- Done: We now compute frustum planes every time, but it is only necessary
  when changing camera projection... Now Frustum (planes) are cached.

- Done: It might be good to separate exotic data formats needed in VBOs to
  their own source file.

- Done: Stupid user error, didn't change the field type at 2D shader side.
  (unsigned short does not work as UV coordinates. Colormaps on 3D models
  work without problem, but not on 2D objects (e.g. text and pacman).
  Investigate the problem. It is also true, that UV coordinates can be
  larger (absolute value) than 1.0, so it could be better to look for
  half floats.)

- Done: UV coordinates are sent as half floats

- Done: attrib function needs a mechanism to automatically choose correct attribute
  binding based on the Mesh.VERTEX types, just like uniforms work. Current
  implementation is a bit clumpsy, but it works.

- Done: "static if" now forces vertex data to be 32 bytes. It would be nice to
  have automatic padding, but even this is a step forward to improve GPU cache
  performance.

-------------------------------------------------------------------------------

Version something:

- Done: (GL) VAOs not working, maybe because of OpenGL version? No, it was
  just some missing code in certain positions.

- Done: Implement interleaved vertex attribute arrays. Interleaved data is
  definitely the easiest one from programming side, I just didnt know how
  to implement it when started developing the engine.

- Postponed: Joystick support; don't forget feedback. Sadly, my game controller
  has no force feedback.

- Done: Normal mapping

-------------------------------------------------------------------------------

Version something:

- Done: Wavefront obj files: Compute (face) normals, if they are missing

- Done: Shape class: We need Layer.Instance 'stencils', or color & texture
  in Mesh: most of time, at least texture is strictly bound to mesh, and will
  not work at other meshes.

- Done: Basic CPU-side bitmap manipulation

- Done: Object hierarchies: parenting cameras and lights to 3D space, very
  much needed feature. Somewhat done...

- Done: Currently, parent objects need not to be in draw lists. How about
  naming them bones?

- Done: Now matrix transform hierarchies are encapsulated under Bone
  class. It can be parented, and it is not part of Scene drawing lists.
  This may cause some problems to clean up "bones" when deleting
  3D objcts?

-------------------------------------------------------------------------------

Version something:

- Done: Fiber cleaning... Fiber list is now a class. Going out of scope
  destroys it.

- Done: Get rid of game.start() - now e.g. performance timers are created
  automatically if they are requested.

- Done: Fonts (TTF font loading & rendering)

- Done: Frustum culling using bounding spheres.

- Done: With Fibers, at least. Some sort of mechanism to create 'temporal'
  objects to layer: for example, explosions and such, which have known & limited
  life time.
  
- Done: Textures from sheet images

- Done: When creating Layer instances, pass them to shader to prepare them (filling
  missing values with reasonable defaults)

