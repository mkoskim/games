*******************************************************************************

DONE:

- NOTE! Text rendering not working!

*******************************************************************************

WORKLIST:

- Shader family: It could be time to concentrate on shader management
  before going forward:
  
  * Shader family: to upload stuff to GPU w/o creating actual shader
  
    - Problem: for binding VBOs and VAOs, the shader program needs
      to be active...
  
  * Shader compilation: for error reporting, would be good to create
    "precompiled" libraries. I have a feeling that I can never make
    error reporting reliable (w/ current OpenGL implementation) for
    "preprocessed" sources, so it would be best to compile GLSL files
    just as the programmer made them.

  * Mesh to intermediate format, separate VAO buffer creation to
    shader family upload. It can be local buffer, as it is consumed
    during OpenGL download.
    
  * Move default shaders to ext/ directory... Would be better to locate
    them to stock/ - or create a new directory for defaults...

- I would need to collect some default setups to e.g. ext/ directory,
  so that I could work at higher levels without needing to worry about
  low level changes.

- "CPU rendering": Rendering objects without uploading them to shader.
  This would be good for example for debugging (rendering normally
  invisible things).

- Move default shaders under ext/ directory (?)

- "Debug channel" to rendering batches: adding a debug mesh to an object
  will be sent there.
  
- It would be nice, if we could direct nodes / entire groups to
  "Wireframe shader"

- CONSIDER SERIOUSLY adding scripting support for asset loading! The idea
  here is, that e.g. lua scripts to load specific things are stored with
  the models, and thus they are stored to BLOB, too - no need for complex
  building mechanism to include correct converters to compiled program.

- Decals (for targeting circles)

- Examine, if BLOB could support symbolic links

- Color for text

- Maybe we use SDL rendering for GUI? Just to get rid of artifacts?

- Maybe own dedicated 2D shader for GUI?

*******************************************************************************

MISC: Yet uncategorized "Post-It" notes...

- License - as things fall under default copyright laws without license,
  I need to think about this. Is it PD or MIT?
  
        Check: http://choosealicense.com/

- "Multi-material" meshes: It would be good to think about the
  implementation a little bit, so that it would fit to future development.
  Quickly the current thought:

        VBO + IBO   0   ... x       MeshPart 1
                    x+1 ... y       MeshPart 2
                    ...
        
  MeshPart is an IBO range. When rendering, you can keep both VBO
  and IBO binded, while changing material between next range.
  
  This is just not necessarily enough, as you may want to render parts
  in different rendering stages. As a simple example, consider a tree.
  Trees are usually constructed so that trunk and larger branches are
  solid meshes, while leafs and small branches are transparent textures.
  
  What you want, is to separate solid and transparent parts to different
  rendering stages.

- Mipmaps

- Node modifiers: Add support for "multi-textured" nodes - the idea is to
  have sort of "stamping", textures over textures. We add node-specific
  material modifiers at some point (like color modifier, but at the same time,
  we could add texture modifiers, too).

- Start working with navigation. The first step is to create a network
  of nodes suitable for pacman-like games.

- Renderers in layer.d are incomplete hacks. Reorganize them, so, that
  move simplified solutions to ext/simple.d (that's the purpose of it)

- Node/Model classification. We assume, that no model (part) ever is added
  to two batches in single stage. So, what we need, is to know to what
  batch the part is added in different stages:
  
        class Model {
            VAO vao;
            struct Part {
                Batch[Stage] destination;
                material;
                (IBO) range;
            }
        }

  For example: We have two rendering pipelines, one for rendering view,
  one for rendering shadow maps. We have tree, that contains several
  materials, some of them solid, some of them transparent:
  
        tree.trunk.destination[viewrender] = viewrender.solid
        tree.trunk.destination[shadowrender] = shadowrender.solid
        
        tree.leafs.destination[viewrender] = viewrender.transparent
        tree.leafs.destination[shadowrender] = shadowrender.transparent

  Basically, we could also use some kind of tagging to locate correct
  batch. We would then also need information to which rendering stages
  the model/part is included:

        viewrender.tag = "visual";
        viewrender.solidbatch.tag = "solid";
        
        shadowrender.tag = "shadowcaster";
        shadowrender.solidbatch.tag = "solid";
        
        ...
        ...

        model.tags = ["visual", "shadowcaster"];
        model.part.tag = "solid";

- Also, it might be very good idea now to separate resource management,
  instead of keeping references in the batches. So, even thought it
  means more writing, we do the thing something like this:
  
        resources.model = shaderfamily.upload(mesh, material);
        resources.model.destination[pipeline] = pipeline.batchX;
        ...

  There is some ways to ease writing code, but anyways, the general idea
  is that references to uploaded models are found only from:

        1) nodes in scene
        2) resource lookup table for scene

  Destroying scene destroys also resources loaded for that.

- Add "persistent" flag to Batch. Even regular 3D game can have
  rendering objects that are persistent (no need for visibility checks,
  and always rendered), common example is skybox:
  
        batches.solid = batch.front2back
        batches.transparent = batch.back2front
        batches.skybox = batch.persistent
        
        batches.skybox.add(skybox);

-------------------------------------------------------------------------------

HOTTISH TOPICS:

- TEXT OUTPUT: This has troubled me a long time, is there anything I can
  do for it? Let's think about it.
  
  There is definitely many ways to get text in to screen. What method to use
  depends on the purpose.
  
  The first and most obvious two ways to render text are:
  
  1) Create a bitmap from given text, and add it to game world as a textured
     rectangle.

  2) Create bitmaps from letters, and add letters to game world as textured
     rectangles.

  These two ways create text that can be manipulated in the same ways as
  any other game world object. You can move them around, animate them and
  so on.
  
  Then, there is third way, which I have used so far. It works more like
  drawing letters to canvas-like object: you don't have 'handles' to
  separate letters, instead they are emitted by the text object.

  So: maybe I (need to) create all these methods? Well, at least two
  first ones are eventually mandatory, for example, for floating
  points and other written information in the game world itself. The
  third one then, at the moment it feels that it is related to creating
  rendering mechanism for GUI purposes: so, at the moment it feels
  totally worth to examine.

- In fact... If we would have support for "emitters" in nodes, we
  could feed objects like that to default shading process. Shader should
  just understand to query the emitted objects... Would be like "poor
  man's particle engine"...

-------------------------------------------------------------------------------

FIX/INVESTIGATE: Crashes, flaws etc.

- Font rendering fails randomly:

    http://stackoverflow.com/questions/26956658/sdl-ttf-rendertext-blended-fails-randomly

- On 32-bit Ubuntu, SDL FillRect segfaults (code that cuts textures from
  sprite sheet).

- Freeing fonts cause segfault (most probably, TTF is already closed when
  calling font destructor)

- Shader compiler (see gpucompiler.d) can only report error location for
  noveau driver. Needs (1) driver detection, and (2) custom reporting for
  each driver.

- glVertexAttribPointer returns invalid enum when trying to use
  GL_INT_2_10_10_10_REV for normals & tangents.

- With normalized integer vectors (see gputypes.d), we use scaling, but
  in reality (for 8-bit) -1 -> -128, +1 -> +127.

- TBN calculation in current shader has its flaws (not normalized nor
  orthogonal in fragment shader), but it might be so that it has no
  significant effect to rendering result

- Current Bone implementation has a transformation cache. It is unclear to me,
  how it works with games loading levels (that is, does it cause memory leak).

- TextBox currently has no color: it is waiting color to be added to
  instance specific modifier.

- wolfish (and cylinderium) generally run at least as fast as pacman, although
  they use much more complicated CPU and GLSL code. I need to investigate 2D
  performance, as because of GUI elements it will matter to 3D games, too.

-------------------------------------------------------------------------------

"USER-FRIENDLINESS": Some planned efforts to make code more "user-friendly":
more portable (32-bit, 64-bit, Linux, Windows), easier to set up, and so on.

- SDL FillRect & Font rendering segfaults on 32-bit machine

- It would be nice to add D doc comments, at least test it. Finally, it would
  be nice if I could make it to compile with dub, and use dub registry.

-------------------------------------------------------------------------------

USER INPUT:

- Keyboard emulated game controller

- Make game controller optional, at least for games that does not need them
  that much (i.e. have also keyboard control)

-------------------------------------------------------------------------------

GENERAL:

- Static linking: examine possibilities to link needed libraries
  (SDL?) statically to remove system side dependencies.

- VBO updating - or, in fact, "CPU-side" VBOs, mainly for instanced draws
  like particle engines. See e.g.
  
  * https://www.opengl.org/wiki/Buffer_Object_Streaming

  * http://www.opengl-tutorial.org/intermediate-tutorials/billboards-particles/particles-instancing/

- Layer <-> geom needs reference point... This is/was intented to help creating
  2D HUD & games. It may be so that 2D games get their own Scene class some
  day? And anyways, geom module has had not much to do with 3D graphics ever
  since implementing Wavefront loader.

- Maybe some offline tools for processing images, meshes and materials?

- Do some debugging aids: Seeing matrices etc.

-------------------------------------------------------------------------------

LOADERS, FILE FORMATS: We started to use Assimp to load model files. Some
design, sketching and planning is needed, as well as tuning the render
architecture more suitable for models loaded from files.

- Blender file (archive) loading

- COLLADA file loading. This project has some possibly interesting
  Collada files to try out:

    https://bitbucket.org/EricPoggel/yage/src/c12a0715d0a7?at=default

- BLOB "attachments": Larger games probably like to have separate resource
  files to ease updating. Without breaking existing behaviour, this could
  be done so that it is possible to include external archives/directories
  to look up for files.
  
- BLOB: Game saving: At some point, we need to add file writing to the engine.

- Wavefront loader: smoothed normals

- Wavefront loader & mesh-material pairs: Wavefront file format has
  groups (s[moothing group], g[group), which could be used to load
  mesh-material pairs, so that they can use same VBOs. Between each
  batch, we change IBO and material - nah, no need, we can give
  range to drawing command, and thus keep the same IBO.

-------------------------------------------------------------------------------

RESOURCE TRACKING: Create mechanism to track living resources (number of
meshes, nodes etc).

- At some point, there's a need to check that destructors are called at
  correct points. For example, when game level is changed, it would be
  very nice if the game frees GPU resources allocated at previous level.

-------------------------------------------------------------------------------

FIBERS, EVENT PROCESSING:

- It would be good to be able to send events to be processed by a Fiber.
  If we have player Fiber, we might want to get the input events there.
  Think & design how to do this.

- It might be good, that FiberQueue callbacks return boolean value
  if they want to continue processing, or if they want them removed. Other
  way to do that would be adding the calling queue to parameters, so that
  callback can remove itself if wanted

- It would be good to implement (frame) timers to Fiber queue.

- simple.gameloop may need a function to determine loop breaking? That
  could simplify certain things...

- Check vibe.d for ideas for game actors (fibers)

-------------------------------------------------------------------------------

SHADERS: Shaders are so central part that they reserve their own section
here. Shader is connected to at least objects, materials and scenes, so these
issues have their relations to other sections in this TODO document.

- I should go to version 130 with shaders. For creating compatible shader
  banks, it is mandatory to ensure that attributes are at the same location.
  Otherwise, loaded VBOs do not work.

- We could accept reading/writing inexisting uniforms in some cases, that is,
  store -1 to namecache. Certain uniforms are optional as their nature, it
  would not hurt if they do not exist in shader. This might not be a good idea
  in general - I want to catch errors early, and this could hide them, causing
  lots of time wasted in debugging.

- Half-done: Improve introspection: dumping uniforms etc at compilation module, to
  help improving & debugging shaders.

- Design "multi-shader" shader: A shader that has several compiled shader
  programs, that can share the same instances.

- Some sort of batch processing with shaders? See:

    * http://www.gamedev.net/page/resources/_/technical/opengl/opengl-batch-rendering-r3900

- It is possible to compile GLSL library code to shader program, and then
  link multiple of these programs together with specific main(). Investigate
  this:
  
      http://stackoverflow.com/questions/9168252/attaching-multiple-shaders-of-the-same-type-in-a-single-opengl-program

- Think Shader subsystem. We would like to have specialized shaders for
  particle engines, not using the regular mesh-material data structures.

-------------------------------------------------------------------------------

OPTIMIZATIONS: While optimizations are not that important, here is some list
of optimizing features I might consider for implementing. For that purpose,
keep these in mind so that architecture does not prevent implementing these:

- Organize triangles to strips, study primitive restart:

    * glEnable(GL_PRIMITIVE_RESTART)​
    * glPrimitiveRestartIndex(65535)​
    * https://www.opengl.org/wiki/Vertex_Rendering#Primitive_Restart

- Sorting drawing so that the same vertice is preferably used in consecutive
  calls, to improve GPU cache performance.

- Think if it is possible automatically pad things:

    "Padding is added to make the vertex structure a multiple of 32 bytes
     since some GPUs prefer it that way, such as ATI/AMD."

    https://www.opengl.org/wiki/Client-Side_Vertex_Arrays

-------------------------------------------------------------------------------

SCENES, LAYERS:

- I'm still not entirely satisfied with the current system. It is currently
  possible to use batch groups directly as scene graphs, which is basically
  good for games like pacman. But:
  
  * We should have node sorting (front to back, ...): It is possible
    to do at draw function, thought.
  
  * We could remove viewing information from scene node, and add it
    to batch node.

- How about making unbuffered batch? Currently, nodes are buffered to
  batch, but we could send them directly to shader: basically, if
  first batch in batch group is unordered, it could be unbuffered, too.
  There is - of course - problem to determine when render state block
  is applied...

- Store viewing information to batch node, not to scene node.

- Some simple file format to create scenes (placing objects, creating
  object hierarchies, ...) could be useful. POVRay may be too complex.
  Something that can be used together with .obj & .mtl files... Of
  course, we need support to other mesh data formats, too, but .obj is
  quite common & useful anyways.

- Probably it is better to classify objects at Layer/Scene level already...
  Keeping objects in one single list helps lookups, but (1) I assume that
  they are more rare operations than rendering calls, and (2) that can
  be simulated anyways (lookup looks from all lists).
  
  * Look at Cylinderium: it has 2 interleaved scenes, one for mother ship,
    one for star field. We might consider generalizing something similar?

- Because of this, it might make some sense to bind lights, visibility
  checks and such to camera. The same information could then be used
  by all scene layers. Need thinking...

- Fog

- Skybox: Cylinderium could use this, in addition to star field. Skybox
  does not replace star field - star field is three dimensional, skybox
  is basically just two dimensional background image.

- Occlusion queries?

    * https://www.opengl.org/wiki/Query_Object#Occlusion_queries

-------------------------------------------------------------------------------

3D OBJECTS:

- Reconsider rotation, it's very unintuitive at the moment. Currently you
  need to make parent hierarchies to keep rotations in order...

- Currently, we have Grip class, that generates transform matrices from
  position, rotation and scaling. It is possible, that we need also
  other ways to generate transform matrices - so, be prepared for that.
  
- Scaling is not entirely working, mainly because it would need updating of
  bounding sphere.

- Points & lines: (1) in meshes, separate points, lines and triangles
  (different IBOs for each; combine somehow with material groups). Think
  a system to tell point size (glPointSize), and finally, we might have
  particle engine...
  
  * In fact: Meshes are meshes. Lines and points are rendered by different
    shaders, or at least, they form different kind of objects, not meshes.
    
- Multiple mesh-material pairs in same object: Maybe with vertex groups?
  Adding IBO-Material pairs to VAOs? No need for separate IBOs, just start
  index for each batch.

- Winding: In case that winding is incorrect when loading a model, we
  could have methods in Mesh class to try to fix it. At least, this
  would be better than changing winding parameter (CW / CCW) when
  rendering.

- Ways to extend Mesh class. Some way to attach more vertex data to
  Mesh so that Shader understands it, for example, skeleton.

- LOD, Level of Detail: like textures have mipmaps, 3D objects could also have
  representations in various details. Including materials. And shaders? No
  need for high-quality shading for low-detail objects.

- Billboards and imposters

- Half-done: Instanced rendering: Layers with single mesh type for OpenGL
  instanced rendering? Probably no, it is probably better idea to have "instanced
  instance", instance with single shape and multiple positions. But well...
  Maybe a particle layer is not a bad idea? Need thinking...
  
- Where instanced rendering would perform best? If there is multiples of same
  mesh near each other, then we could take the advantage of both worlds:
  having efficient CPU-side prunings, AND instanced rendering. For example,
  branches and leaves in a tree.

- Investigate using of GL_ARB_vertex_attrib_binding functions to bind
  buffers and attributes, instead of glVertexAttribPointer.

-------------------------------------------------------------------------------

PARTICLE & SPRITE ENGINE: It might be nice to have specialized
classes to blit lots of things into 2D/3D space.

- Particle engine can (most probably) have only 1 texture. So, the solution
  is to create sprite sheets?
  
- Anyways, there are probably at least three different sprite engines:

  1) Lowest performance engine works like current TextBox: We could add
     depth things there, so that you could draw text background *after*
     printing the text. Or can we? It will be tricky...

  2) Highest performance engine is "regular" particle engine.

- We might want to separate static and dynamic sprite engines: backgrounds,
  starfields and such would be rendered by static engine, moving sprites
  by dynamic engine.

-------------------------------------------------------------------------------

ANIMATION:

- Animation

- EasingCurve: http://qt-project.org/doc/qt-4.8/qeasingcurve.html

- Blender: http://wiki.blender.org/index.php/Doc:2.6/Manual/Animation

- One tough question: How to update bounding volumes on animated meshes?
  Use coarse approximation?

- Easy curve generator to tools... Some curves are easier to generate
  numerically with simulator...

-------------------------------------------------------------------------------

LIGHTS, MATERIALS: Lights and materials are fragment shader inputs. It would be
good that these are generic (but simple enough) to support different kinds of
shaders.

- Design light management... Shaders will always possess limitations to how
  many lights they can handle per object

- Shadows

- Study other shading models

- Half-done: Design some sort of mechanism for some uniform material parameters,
  so that you can change shading model and still have somewhat similar results

- It would be nice to have some kind of "database" system for materials,
  combining e.g. color & normal maps and roughness together, so that you
  could load materials with fewer lines in the code. Similarly, there
  could be data files for other assets like sprite sheets (describing the
  dimensions of the sheet) for loading them with less efforts.

- It might be wise to move normal maps from material to "mesh": it is more
  like added geometry than a material parameter... Although it can be
  that, too...

-------------------------------------------------------------------------------

CAMERA:

- Viewport settings to camera... In fact, create sort of RenderTarget
  class.

- View, ViewProxy: I havent used View proxy ever. There is a need to
  check if it has any use at all, or if we could simplify things a bit.

-------------------------------------------------------------------------------

BITMAPS:

- Some sort of "tile toolkit" to create tiles

- Also, some sort of normal map toolkit to create normal maps

-------------------------------------------------------------------------------

TEXTURES:

- Texture mipmaps: In 3D scenes, this could make them prettier.

- Texture update

-------------------------------------------------------------------------------

TEXTBOX, GUI:

- The way TextBox is implemented prevents us to implement shaders as
  instance batch processors. We may reconsider that implementation.

  * In fact, currently TextBox is more like special "Layer", not instance
  
  * I feel that the way TextBox works might be suitable for e.g. particle
    engines. So, instead of changing the TextBox implementation, we might
    improve architecture to deal with these kinds of things.

-------------------------------------------------------------------------------

FONTS:

- For some reason, rendered text at plain alpha channel does not work. Investigate

- Half-done: Bitmap sheet loading need to be generalized, needed for both text
  and (at least 2D) game objects 

- At some point, we need to modify text to support UTF-8 (for moe3d)

- Investigate possible alternative solutions for rendering (HUD) text. Maybe rendering
  at CPU, and using subtextures?
  
- Also, we could use GPU to scale letters, no need to create font for all sizes. Check
  the result.

- Also, current system is made for HUD (screen coordinates), design a way to use it
  for 3D objects

-------------------------------------------------------------------------------

SOUNDS:

- Think a little bit about them...

-------------------------------------------------------------------------------

ARCHITECTURE:

- Shaders and layers... VAOs, VBOs and such, they are sort of bind to shader.
  At some point, we might need to ensure that shader can't be switched after
  meshes in layer are bind to certain shader. Or something like that.

-------------------------------------------------------------------------------

LOW PRIORITY:

- Display lists are still useful??? Find it out.

- Study Manhattan distance to be used as quick way to filter nearby elements

