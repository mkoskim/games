*******************************************************************************

SKETCHING: This is general-purpose file to put down ideas for future
development.

*******************************************************************************

-------------------------------------------------------------------------------

LIGHTING FRAMEWORK:

BACKGROUND: This is something that I have been thinking a while. Many 3D
engines and editors add lights to scene graph nodes. But:

    * The maximum number of lights is (1) shader specific constant (2) for
      every individual rendered object.

    * The "visibility" of light is determined if objects it lights are
      visible - not the visibility of the light source itself.

So, my basic approach to lights is following:

    1) Use camera to fetch visible objects
    
    2) Fetch lights that affect to those objects
    
    3) For each light found, at least for shadow casting ones,
       render shadow map
    
    3) For each object, when rendering, choose the set of lights,
       based on the limitations of the shader.

In a game, we already have several "spaces": we have visible (rendered)
space, we have physical space, we have navigation meshes ("AI space"),
and so on. So, what about creating "light space"?

What is "light space"? It determines which lights to set up for an
*object* to be rendered.

As a very crude example: For each object we render, we go through
all lights in the current scene, and sort them by how much they
light the object. Then we choose N strongest lights for rendering.

QUESTION: This can - of course - be very heavy operation. So, the fundamental
question here is, how we can define "light space" to decrease the
number of possible lights when rendering an object? As with real time
3D rendering in general, what kind of cheap tricks we can use?

-------------------------------------------------------------------------------

RENDERING FRAMEWORK:

The current (May 11, 2015) idea is to change underlaying architecture
considerably. Thoughts I have:

- Shader class becomes just interface between CPU and GLSL. It has
  methods to upload and update data structures needed by GLSL. I should
  separate shader data structures from the ones used by game.
  
- 'Layers' and such are combined with Shader to create yet unnamed
  object, that holds uploaded data, and feeds batches to shader.

- Different kind of batch processors: spritesheet blitter, generic
  3D blitter, text blitter, ...

- Game combines several such objects to form a pipeline to render
  the screen.

What I can be quite certainly sure, is that we have Shader object(s), and
we have collections of instances that are fed to shader to render. At high
levels, we have higher level game objects and their grouping. Then we have
'middleware' to construct shader work sets from high level game objects,
based on different criterias (like camera position).

We know that what we are doing, is to generate draw instructions to
OpenGL from high level data structures.


    High                         OpenGL
    Level      ---> magic --->   Function
    Game                         Calls
    Objects

- - -

Lets start from very simple mechanics.

    Group<Instance> ---> Shader

We have simple unordered group of instances (instance holds data needed
for rendering: shape, material, position). It is directly fed to shader
to render.

To go further, we create several groups, and feed them to Shader in
specific order to ensure correct drawing order:

    Group<Instance> ---> Shader
    Group<Instance> ---> Shader

We might want to have specialized groups. One example is to have a
instanced group - a group that 'clones' specific shapes. For example,
spaceships in a fleet, or particles in an explosion, or a star field.

    Clone<Shape, Pos> ---> Shader
    Group<Instance>   ---> Shader

Both freeform instance group and cloning group should work together.

FRUSTUM CULLING, DRAWING ORDER: So far, so good. But then, we might want to
apply different kind of filters and such for optimizing larger scenes.

    |-- Source ---|
                        |---------- Filtering ----------|

    Group<Instance> --> Frustum Culling --> front-to-back --> Shader
    Group<Instance> --> Frustum Culling --> back-to-front --> Shader
    
The first one, drawing objects from front-to-back, works well for
solid objects with fragment heavy shaders. The latter one is needed
to (somewhat) correctly render transparent objects.

Frustum culling is an example of exclusive filtering. Somewhat similar
is occlusion culling (using occluders). An example of inclusive filter
are portals.

INSTANCED DRAWING: Filtering phase should also work with instanced
drawing.

- - -

ROOMS AND PORTALS: The idea here is that there is a network of Rooms,
which are connected to each other with portals. Camera is located in
one specific room. Everything inside a room is included. For portals,
we do frustum culling, and for every visible portal, we include
items from the target room, using portal as 'frustum culling'.

Rooms & Portals have my main interest, as many of the projects I am
planning are more or less dungeon based games.

BTW: Portals are single faced. So, in addition to check if they are
inside frustum, it is also necessary to check if we are looking
its front face. For example, consider a hut with a door in a landscape:
if we are looking the hut from back side, even that the portal is inside
frustum, it is at the opposite side.

-------------------------------------------------------------------------------

USER INPUT: Personally, I'm designing games to be controlled with game
controller (XBox 360). The reason for this is that keyboard controlling is
too coarse for the main projects I have been thinking (e.g. Skyrim-like
stealth that is dependent on movement speed), and on the other hand, I have
never learnt to use mouse in games.

But not all games need or benefit from game controller, for example pacman.
I need a system to hide 'dirty details' that is easy to use in games. It may
also give some configurability. Some current thoughts:

    * Keyboard & mouse emulated game controller

    * One more indirection layer, a configurable logical controller, which
      connects to the actual controllers.

One way could be to create a bunch of "logical controllers": one would be
simple 4-direction joystick for pacman-like games, some other would contain
more directions (that is, movement + look) and buttons.


